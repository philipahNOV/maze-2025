raceback (most recent/  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/student/Documents/maze-2025/jetson/src/zed_test/detector.py", line 113, in trt_thread
    trt_model = TRTInference(engine_path)
  File "/home/student/Documents/maze-2025/jetson/src/zed_test/detector.py", line 85, in __init__
    self.d_input = cuda.mem_alloc(self.input_size)
pycuda._driver.LogicError: explicit_context_dependent failed: invalid device context - no currently active context?
 File "/home/student/Documents/maze-2025/jetson/src/zed_test/detector.py", line 104, in infer
    cuda.memcpy_dtoh_async(output_data, self.d_output, self.stream)
pycuda._driver.LogicError: cuMemcpyDtoHAsync failed: an illegal memory access was encountered

de 1: Cuda Driver (an illegal memory access was encountered)
[07/30/2025-12:19:09] [TRT] [E] 1: [cudaDriverHelpers.cpp::operator()::94] Error Code 1: Cuda Driver (an illegal memory access was encountered)
[07/30/2025-12:19:09] [TRT] [E] 1: [cudaDriverHelpers.cpp::operator()::94] Error Code 1: Cuda Driver (an illegal memory access was encountered)
PyCUDA WARNING: a clean-up operation failed (dead context maybe?)
cuMemFree failed: an illegal memory access was encountered
PyCUDA WARNING: a clean-up operation failed (dead context maybe?)
cuMemFree failed: an illegal memory access was encountered
PyCUDA WARNING: a clean-up operation failed (dead context maybe?)
cuStreamDestroy failed: an illegal memory access was encountered
-------------------------------------------------------------------
PyCUDA ERROR: The context stack was not empty upon module cleanup.
-------------------------------------------------------------------
A context was still active when the context stack was being
cleaned up. At this point in our execution, CUDA may already
have been deinitialized, so there is no way we can finish
cleanly. The program will be aborted now.
Use Context.pop() to avoid this problem.




Initialized Camera
[07/30/2025-12:23:39] [TRT] [I] Loaded engine size: 15 MiB
[07/30/2025-12:23:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +12, now: CPU 0, GPU 77 (MiB)
[07/30/2025-12:23:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +69, now: CPU 1, GPU 146 (MiB)
/home/student/Documents/maze-2025/jetson/src/zed_test/detector.py:79: DeprecationWarning: Use get_tensor_name instead.
  self.input_binding_idx = self.engine.get_binding_index(self.engine[0])
/home/student/Documents/maze-2025/jetson/src/zed_test/detector.py:80: DeprecationWarning: Use get_tensor_name instead.
  self.output_binding_idx = self.engine.get_binding_index(self.engine[1])
/home/student/Documents/maze-2025/jetson/src/zed_test/detector.py:83: DeprecationWarning: Use get_tensor_shape instead.
  self.output_shape = self.engine.get_binding_shape(1)
0.0
Exception in thread Thread-1 (trt_thread):
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/student/Documents/maze-2025/jetson/src/zed_test/detector.py", line 123, in trt_thread
    trt_output = trt_model.infer(image_net)
AttributeError: 'TRTInference' object has no attribute 'infer'
-------------------------------------------------------------------
PyCUDA ERROR: The context stack was not empty upon module cleanup.
-------------------------------------------------------------------
A context was still active when the context stack was being
cleaned up. At this point in our execution, CUDA may already
have been deinitialized, so there is no way we can finish
cleanly. The program will be aborted now.
Use Context.pop() to avoid this problem.
